# -*- coding: utf-8 -*-
"""EDA_Tesla.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FnEnrY7Tebq7cMUFjCJZQgk0x_11WKEO

# Importing necessary libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os

"""# 1. Data Loading and Basic Information"""

import pandas as pd

# Load the dataset
file_path = '/content/tesla_stock_data_final_cleaneddata(noduplciates_nomissingvalues).csv'
df_filled = pd.read_csv(file_path)

# Convert 'timestamp' to datetime format and set it as the index
df_filled['timestamp'] = pd.to_datetime(df_filled['timestamp'])
df_filled.set_index('timestamp', inplace=True)

# View the first few rows of the data
print(df_filled.head())

"""# 2. Dataset Information and File Details"""

import os

# Define the file path
file_path = '/content/tesla_stock_data_final_cleaneddata(noduplciates_nomissingvalues).csv'

# Check the size of the CSV file (in bytes)
file_size = os.path.getsize(file_path)

# Convert bytes to MB
file_size_mb = file_size / (1024 * 1024)

# Print the file size in MB
print(f"File size: {file_size_mb:.2f} MB")

# Print basic info and stats
print(f"Dataset Shape: {df_filled.shape}")  # Rows and columns
print(f"Data Types:\n{df_filled.dtypes}")

"""# 3. Missing Values and Duplicates"""

# Check for missing values in each column
print(f"Missing values:\n{df_filled.isnull().sum()}")

# Check for duplicates in the dataset
duplicates = df_filled.duplicated()

# Print the number of duplicate rows
print(f"Number of duplicate rows: {duplicates.sum()}")

# Optionally: Show the duplicate rows
print(f"Duplicate rows:\n{df_filled[duplicates]}")

"""# 4. Visualizing High Prices Over Time"""

import matplotlib.pyplot as plt

# Visualizing High prices over time
plt.figure(figsize=(12, 6))
plt.plot(df_filled['high'], label='High Price', color='red', alpha=0.6)
plt.title("Tesla Stock High Price Over Time")
plt.xlabel('Timestamp')
plt.ylabel('Price')
plt.legend()
plt.show()

"""# 5. Visualizing Low Prices Over Time"""

import matplotlib.pyplot as plt

# Visualizing Low prices over time
plt.figure(figsize=(12, 6))
plt.plot(df_filled['low'], label='Low Price', color='blue', alpha=0.6)
plt.title("Tesla Stock Low Price Over Time")
plt.xlabel('Timestamp')
plt.ylabel('Price')
plt.legend()
plt.show()

"""# 6. Summary Statistics for Each Column"""

# Print unique values in each column
print(f"Unique values in each column:\n{df_filled.nunique()}")

# Get the highest and lowest values in each column
highest_values = df_filled.max()
lowest_values = df_filled.min()

# Get the timestamp for the highest and lowest values in each column
timestamps_of_highest_values = df_filled.idxmax()
timestamps_of_lowest_values = df_filled.idxmin()

# Display the results
print("Highest and Lowest values in each column along with their timestamps:")
for column in df_filled.columns:
    # Skip the 'date' column
    if column == 'date':
        continue

    highest_value = highest_values[column]
    lowest_value = lowest_values[column]
    highest_timestamp = timestamps_of_highest_values[column]
    lowest_timestamp = timestamps_of_lowest_values[column]

    # Display highest and lowest values with their timestamps
    print(f"{column}:")
    print(f"  Highest Value: {highest_value} at Timestamp: {highest_timestamp}")
    print(f"  Lowest Value: {lowest_value} at Timestamp: {lowest_timestamp}")
    print("-" * 50)  # To separate each column for clarity

"""#7. Dataset Period and Summary"""

# Get the year range from the 'timestamp' column
start_year = df_filled.index.min().year
end_year = df_filled.index.max().year

# Display the year range
print(f"The dataset covers the period from {start_year} to {end_year}.")

# Get a summary of statistics for the numerical columns
print(f"Summary Statistics:\n{df_filled.describe()}")

"""#8. Correlation Analysis"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Select only numeric columns
numeric_df = df_filled.select_dtypes(include=['number', 'float', 'int'])

# Calculate Pearson correlation matrix
pearson_correlation_matrix = numeric_df.corr(method='pearson')

# Plot Pearson correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(pearson_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Pearson Correlation Matrix")
plt.show()

# Calculate Spearman correlation matrix
spearman_correlation_matrix = numeric_df.corr(method='spearman')

# Plot Spearman correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(spearman_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Spearman Correlation Matrix")
plt.show()

"""# 9. Distribution of Key Columns"""

# Plot histograms for selected columns
df_filled[['close', 'high', 'low', 'open', 'volume']].hist(bins=20, figsize=(12, 8))
plt.suptitle("Distribution of Key Columns")
plt.show()

"""# 10. Resampling Data to Daily Frequency"""

# Resample the data to daily frequency (aggregating with max for high, min for low, and sum for volume)
df_daily = df_filled.resample('D').agg({'high': 'max', 'low': 'min', 'volume': 'sum', 'vwap': 'mean'})

# Plot daily high and low prices
plt.figure(figsize=(12, 6))
plt.plot(df_daily['high'], label='Daily High Price', color='red')
plt.plot(df_daily['low'], label='Daily Low Price', color='blue')
plt.title("Daily High and Low Prices")

plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

"""# 11. Boxplots for Outliers in Price-related Columns"""

# Boxplots for detecting outliers in price-related columns
plt.figure(figsize=(12, 6))
sns.boxplot(data=df_filled[['close', 'high', 'low', 'open']])
plt.title("Boxplot of Stock Prices")
plt.show()

"""# 12. Monthly Average High and Low Prices"""

# Calculate monthly average high and low prices
monthly_avg_high = df_filled.groupby('month')['high'].mean()
monthly_avg_low = df_filled.groupby('month')['low'].mean()

# Plot for Monthly Average High Prices
plt.figure(figsize=(12, 6))
plt.bar(monthly_avg_high.index, monthly_avg_high, color='green', label='Average High Price')
plt.title('Average Monthly High Prices')
plt.xlabel('Month')
plt.ylabel('Average High Price')
plt.xticks(monthly_avg_high.index - 1, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.legend()
plt.show()

# Plot for Monthly Average Low Prices
plt.figure(figsize=(12, 6))
plt.bar(monthly_avg_low.index, monthly_avg_low, color='red', label='Average Low Price')
plt.title('Average Monthly Low Prices')
plt.xlabel('Month')
plt.ylabel('Average Low Price')
plt.xticks(monthly_avg_low.index - 1, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.legend()
plt.show()

"""# 13. Weekly Average High and Low Prices"""

# Calculate weekly average high and low prices
weekly_avg_high = df_filled.groupby(df_filled.index.isocalendar().week)['high'].mean()
weekly_avg_low = df_filled.groupby(df_filled.index.isocalendar().week)['low'].mean()

# Plot for Weekly Average High Prices
plt.figure(figsize=(12, 6))
plt.bar(weekly_avg_high.index, weekly_avg_high, color='green', label='Average High Price')
plt.title('Average Weekly High Prices')
plt.xlabel('Week')
plt.ylabel('Average High Price')
plt.xticks(weekly_avg_high.index, weekly_avg_high.index, rotation=45)
plt.legend()
plt.show()

# Plot for Weekly Average Low Prices
plt.figure(figsize=(12, 6))
plt.bar(weekly_avg_low.index, weekly_avg_low, color='red', label='Average Low Price')
plt.title('Average Weekly Low Prices')
plt.xlabel('Week')
plt.ylabel('Average Low Price')
plt.xticks(weekly_avg_low.index, weekly_avg_low.index, rotation=45)
plt.legend()
plt.show()

"""# 14. Distribution of High and Low Prices"""

# Plot histograms for high and low prices separately
ax = df_filled['high'].hist(bins=20, figsize=(12, 8), color='lightgreen', edgecolor='black', alpha=0.7, label='High')
df_filled['low'].hist(bins=20, figsize=(12, 8), color='salmon', edgecolor='black', alpha=0.7, label='Low')

# Add titles and labels
plt.suptitle("Distribution of High and Low Prices")
plt.xlabel('Price')
plt.ylabel('Frequency')

# Show legend
plt.legend()

# Show plot
plt.show()

"""# 15. Boxplot for Outliers in High and Low Prices"""

# Boxplot to detect outliers in high and low prices
plt.figure(figsize=(12, 6))
sns.boxplot(data=df_filled[['high', 'low']], palette='coolwarm')
plt.title("Boxplot of High and Low Prices")
plt.show()

"""# 16. Volume Analysis"""

plt.figure(figsize=(12, 6))
plt.plot(df_filled['volume'], label='Volume', color='purple')
plt.title("Tesla Stock Trading Volume Over Time")
plt.xlabel('Date')
plt.ylabel('Volume')
plt.legend()
plt.show()

"""1. Insight: Strong Correlation Between High and Close Prices
Key Finding: The correlation heatmap between the various stock price features (high, low, open, close) likely shows a strong positive correlation between the high and close prices, which suggests that higher daily high prices tend to correlate with higher closing prices.

Actionable Insight:

Traders or investors can use the high price as a leading indicator of the closing price for a given trading day. If the high price for the day is significantly higher than usual, it could indicate that the stock has bullish momentum, and the closing price may also be elevated.
Impact: This insight can lead to better predictive models and trading strategies, where traders can anticipate the end-of-day price movements based on intra-day highs.
2. Insight: Volume Spikes Precede Price Movements
Key Finding: From the visualizations and volume analysis, you can observe that spikes in trading volume often precede sharp movements in stock prices (either upward or downward). Volume surges are commonly associated with market events such as earnings reports, news releases, or other significant market catalysts.

Actionable Insight:

Volume as a Signal: Traders could use volume spikes as a key signal for price movement. For example, when there is a sudden increase in trading volume, it could indicate an impending price breakout (upward or downward). Combining this insight with technical indicators such as moving averages could help predict the direction of the next price movement.
Impact: This would improve the timing of trades, helping investors to capitalize on potential price changes before they happen, thus leading to higher returns.
3. Insight: Monthly and Weekly Trends in High and Low Prices
Key Finding: The analysis of monthly and weekly average high and low prices indicates possible seasonal patterns or trends. For instance, there may be consistent monthly or weekly variations in high and low prices. Certain months or weeks might show a tendency for higher prices, potentially related to broader market trends, Teslaâ€™s financial calendar, or product releases.

Actionable Insight:

Seasonality: Investors could optimize their trading strategies by accounting for these monthly or weekly trends. For instance, if Tesla historically shows strong performance in certain months (e.g., following product announcements, or at the end of a fiscal quarter), they could align their investment or trading strategies around these times.
Impact: This insight could lead to a more proactive approach, allowing traders to anticipate periods of higher volatility or price movement and adjust their portfolios accordingly to capitalize on those patterns.
Summary of Insights and Impact:
High Price Correlation with Closing Price: Traders can use high prices as predictors for closing prices, helping improve the accuracy of intraday predictions.
Volume Spikes as Indicators of Price Movements: Spikes in volume can signal price movements, allowing traders to adjust their strategies before the price moves significantly.
Seasonal Price Patterns: Recognizing monthly or weekly trends can help investors capitalize on seasonal price movements, optimizing entry and exit points in the market.
By incorporating these insights into trading strategies, organizations and traders can make more informed decisions, manage risk better, and potentially improve returns.
"""