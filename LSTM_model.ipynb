{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH5nBTI3AXLE",
        "outputId": "bef8d494-09a7-462b-a2fa-bdadc4c88d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "close          0\n",
            "high           0\n",
            "low            0\n",
            "trade_count    0\n",
            "open           0\n",
            "volume         0\n",
            "vwap           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/tesla_stock_data_final_cleaneddata(noduplciates_nomissingvalues).csv')\n",
        "\n",
        "# Convert 'timestamp' to datetime format\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df.set_index('timestamp', inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Date-based features\n",
        "df['day_of_week'] = df.index.dayofweek\n",
        "df['month'] = df.index.month\n",
        "df['year'] = df.index.year\n",
        "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)  # Weekend feature\n",
        "\n",
        "# Rolling statistics (7-day and 30-day averages)\n",
        "df['7_day_avg'] = df['close'].rolling(window=7).mean()\n",
        "df['30_day_avg'] = df['close'].rolling(window=30).mean()\n",
        "\n",
        "# Volatility (difference between high and low prices over 7-day window)\n",
        "df['7_day_volatility'] = df['high'].rolling(window=7).max() - df['low'].rolling(window=7).min()\n",
        "\n",
        "# Lag features (previous day, 5 days ago, 10 days ago)\n",
        "df['close_lag_1'] = df['close'].shift(1)\n",
        "df['close_lag_5'] = df['close'].shift(5)\n",
        "df['close_lag_10'] = df['close'].shift(10)\n",
        "\n",
        "# Remove rows with NaN values generated by rolling and lag features\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Function to create the target high and low prices\n",
        "def create_targets(df, n_days=10):\n",
        "    df['target_high'] = df['high'].shift(-n_days).rolling(window=n_days).max()\n",
        "    df['target_low'] = df['low'].shift(-n_days).rolling(window=n_days).min()\n",
        "    df = df.dropna(subset=['target_high', 'target_low'])\n",
        "    return df\n",
        "\n",
        "df = create_targets(df, n_days=10)\n",
        "\n",
        "# Feature columns and target variables\n",
        "X = df[['close', '7_day_avg', '30_day_avg', '7_day_volatility', 'close_lag_1', 'close_lag_5', 'close_lag_10', 'day_of_week', 'month', 'is_weekend']]\n",
        "y_high = df['target_high']\n",
        "y_low = df['target_low']"
      ],
      "metadata": {
        "id": "Ih1PufrlByGk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale features for LSTM\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_features = scaler.fit_transform(df[['close', '7_day_avg', '30_day_avg', '7_day_volatility', 'close_lag_1', 'close_lag_5', 'close_lag_10', 'day_of_week', 'month', 'is_weekend']])\n",
        "\n",
        "# Optimized LSTM data preparation\n",
        "def prepare_lstm_data_optimized(df, features, target_col, sequence_length=30):\n",
        "    data = df[features].values\n",
        "    target = df[target_col].values\n",
        "    num_samples = len(data) - sequence_length\n",
        "\n",
        "    # Pre-allocate memory for X and y\n",
        "    X = np.zeros((num_samples, sequence_length, len(features)))\n",
        "    y = np.zeros(num_samples)\n",
        "\n",
        "    for i in range(sequence_length, len(data)):\n",
        "        X[i-sequence_length] = data[i-sequence_length:i]\n",
        "        y[i-sequence_length] = target[i]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Prepare data for LSTM\n",
        "X_lstm_high, y_lstm_high = prepare_lstm_data_optimized(df, df[['close', '7_day_avg', '30_day_avg', '7_day_volatility', 'close_lag_1', 'close_lag_5', 'close_lag_10', 'day_of_week', 'month', 'is_weekend']].columns, 'target_high', sequence_length=10)\n",
        "X_lstm_low, y_lstm_low = prepare_lstm_data_optimized(df, df[['close', '7_day_avg', '30_day_avg', '7_day_volatility', 'close_lag_1', 'close_lag_5', 'close_lag_10', 'day_of_week', 'month', 'is_weekend']].columns, 'target_low', sequence_length=10)\n",
        "\n",
        "# Train-Test Split for LSTM\n",
        "X_train_lstm, X_test_lstm, y_train_lstm_high, y_test_lstm_high = train_test_split(X_lstm_high, y_lstm_high, test_size=0.2, shuffle=False)\n",
        "X_train_lstm, X_test_lstm, y_train_lstm_low, y_test_lstm_low = train_test_split(X_lstm_low, y_lstm_low, test_size=0.2, shuffle=False)\n"
      ],
      "metadata": {
        "id": "9GyCXXGECrBn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Build smaller LSTM model for High Price\n",
        "lstm_model_high = Sequential()\n",
        "lstm_model_high.add(LSTM(units=30, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))  # Reduced units from 50 to 30\n",
        "lstm_model_high.add(Dropout(0.2))  # Keep dropout for regularization\n",
        "lstm_model_high.add(LSTM(units=30, return_sequences=False))  # Reduced units from 50 to 30\n",
        "lstm_model_high.add(Dropout(0.2))\n",
        "lstm_model_high.add(Dense(units=1))  # Output layer for price prediction\n",
        "lstm_model_high.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the smaller LSTM model for High Price\n",
        "lstm_model_high.fit(X_train_lstm, y_train_lstm_high, epochs=1, batch_size=16)  # Reduced epochs from 1 to 5 for more stable training\n",
        "\n",
        "# Build smaller LSTM model for Low Price\n",
        "lstm_model_low = Sequential()\n",
        "lstm_model_low.add(LSTM(units=30, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))  # Reduced units from 50 to 30\n",
        "lstm_model_low.add(Dropout(0.2))  # Keep dropout for regularization\n",
        "lstm_model_low.add(LSTM(units=30, return_sequences=False))  # Reduced units from 50 to 30\n",
        "lstm_model_low.add(Dropout(0.2))\n",
        "lstm_model_low.add(Dense(units=1))  # Output layer for price prediction\n",
        "lstm_model_low.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the smaller LSTM model for Low Price\n",
        "lstm_model_low.fit(X_train_lstm, y_train_lstm_low, epochs=1, batch_size=16)  # Reduced epochs from 1 to 5 for more stable training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFaf4stOB6g_",
        "outputId": "c683e58d-24d0-4956-b69b-f34906efc0df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m74595/74595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 6ms/step - loss: 158353.9531\n",
            "\u001b[1m74595/74595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 6ms/step - loss: 132767.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d4ec05f100>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_lstm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGvFchK5RB8r",
        "outputId": "113d458a-df55-4159-9978-6e60a63d653f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(298380, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_high_lstm = lstm_model_high.predict(X_test_lstm, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuKhXVBePJbY",
        "outputId": "4cc25938-cbae-48ec-e946-30316d8bda60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m37298/37298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_low_lstm = lstm_model_low.predict(X_test_lstm, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2sBGJ4VR0p2",
        "outputId": "f28d01a2-7199-4818-826c-51e19e5c7bd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m37298/37298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate LSTM model performance for high prices\n",
        "mae_high_lstm = mean_absolute_error(y_test_lstm_high, y_pred_high_lstm)\n",
        "rmse_high_lstm = np.sqrt(mean_squared_error(y_test_lstm_high, y_pred_high_lstm))\n",
        "mape_high_lstm = np.mean(np.abs((y_test_lstm_high - y_pred_high_lstm) / y_test_lstm_high)) * 100\n",
        "r2_high_lstm = r2_score(y_test_lstm_high, y_pred_high_lstm)\n",
        "\n",
        "# Evaluate LSTM model performance for low prices\n",
        "mae_low_lstm = mean_absolute_error(y_test_lstm_low, y_pred_low_lstm)\n",
        "rmse_low_lstm = np.sqrt(mean_squared_error(y_test_lstm_low, y_pred_low_lstm))\n",
        "mape_low_lstm = np.mean(np.abs((y_test_lstm_low - y_pred_low_lstm) / y_test_lstm_low)) * 100\n",
        "r2_low_lstm = r2_score(y_test_lstm_low, y_pred_low_lstm)\n",
        "\n",
        "# Print the evaluation metrics for high price prediction\n",
        "print(\"\\nLSTM High Price Prediction Results:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_high_lstm}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_high_lstm}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape_high_lstm:.2f}%\")\n",
        "print(f\"R-squared (R²): {r2_high_lstm:.4f}\")\n",
        "\n",
        "# Print the evaluation metrics for low price prediction\n",
        "print(\"\\nLSTM Low Price Prediction Results:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_low_lstm}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_low_lstm}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape_low_lstm:.2f}%\")\n",
        "print(f\"R-squared (R²): {r2_low_lstm:.4f}\")\n"
      ],
      "metadata": {
        "id": "8N_VCrHMJhct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define batch size for evaluation\n",
        "batch_size = 5000  # Adjust based on available memory\n",
        "\n",
        "# Initialize lists to accumulate results\n",
        "mae_batch = []\n",
        "rmse_batch = []\n",
        "mape_batch = []\n",
        "r2_batch = []\n",
        "\n",
        "# Evaluate in batches for high prices\n",
        "for i in range(0, len(y_pred_high_lstm), batch_size):\n",
        "    batch_y_true_high = y_test_lstm_high[i:i+batch_size]\n",
        "    batch_y_pred_high = y_pred_high_lstm[i:i+batch_size]\n",
        "\n",
        "    mae_batch.append(mean_absolute_error(batch_y_true_high, batch_y_pred_high))\n",
        "    rmse_batch.append(np.sqrt(mean_squared_error(batch_y_true_high, batch_y_pred_high)))\n",
        "    mape_batch.append(np.mean(np.abs((batch_y_true_high - batch_y_pred_high) / batch_y_true_high)) * 100)\n",
        "    r2_batch.append(r2_score(batch_y_true_high, batch_y_pred_high))\n",
        "\n",
        "# Compute the average of the batch results for high prices\n",
        "mae_high_lstm = np.mean(mae_batch)\n",
        "rmse_high_lstm = np.mean(rmse_batch)\n",
        "mape_high_lstm = np.mean(mape_batch)\n",
        "r2_high_lstm = np.mean(r2_batch)\n",
        "\n",
        "# Reset lists for low price evaluation\n",
        "mae_batch.clear()\n",
        "rmse_batch.clear()\n",
        "mape_batch.clear()\n",
        "r2_batch.clear()\n",
        "\n",
        "# Evaluate in batches for low prices\n",
        "for i in range(0, len(y_pred_low_lstm), batch_size):\n",
        "    batch_y_true_low = y_test_lstm_low[i:i+batch_size]\n",
        "    batch_y_pred_low = y_pred_low_lstm[i:i+batch_size]\n",
        "\n",
        "    mae_batch.append(mean_absolute_error(batch_y_true_low, batch_y_pred_low))\n",
        "    rmse_batch.append(np.sqrt(mean_squared_error(batch_y_true_low, batch_y_pred_low)))\n",
        "    mape_batch.append(np.mean(np.abs((batch_y_true_low - batch_y_pred_low) / batch_y_true_low)) * 100)\n",
        "    r2_batch.append(r2_score(batch_y_true_low, batch_y_pred_low))\n",
        "\n",
        "# Compute the average of the batch results for low prices\n",
        "mae_low_lstm = np.mean(mae_batch)\n",
        "rmse_low_lstm = np.mean(rmse_batch)\n",
        "mape_low_lstm = np.mean(mape_batch)\n",
        "r2_low_lstm = np.mean(r2_batch)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\nLSTM High Price Prediction Results:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_high_lstm}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_high_lstm}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape_high_lstm:.2f}%\")\n",
        "print(f\"R-squared (R²): {r2_high_lstm:.4f}\")\n",
        "\n",
        "print(\"\\nLSTM Low Price Prediction Results:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_low_lstm}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_low_lstm}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape_low_lstm:.2f}%\")\n",
        "print(f\"R-squared (R²): {r2_low_lstm:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30pjNYaKJ2DC",
        "outputId": "6aabdde8-71a9-4aec-af1c-1953ed51925e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM High Price Prediction Results:\n",
            "Mean Absolute Error (MAE): 198.9777047401231\n",
            "Root Mean Squared Error (RMSE): 199.49948937816083\n",
            "Mean Absolute Percentage Error (MAPE): 79.29%\n",
            "R-squared (R²): -1429.8249\n",
            "\n",
            "LSTM Low Price Prediction Results:\n",
            "Mean Absolute Error (MAE): 568.8057764990039\n",
            "Root Mean Squared Error (RMSE): 570.2081253210392\n",
            "Mean Absolute Percentage Error (MAPE): 229.73%\n",
            "R-squared (R²): -11688.5069\n"
          ]
        }
      ]
    }
  ]
}