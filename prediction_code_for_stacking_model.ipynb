{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OVcCblNoCFO"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the input date for prediction\n",
        "def preprocess_date_input(input_date, df, training_columns):\n",
        "    \"\"\"\n",
        "    Preprocess the input date to generate the necessary features for prediction.\n",
        "    \"\"\"\n",
        "    input_date = pd.to_datetime(input_date)\n",
        "\n",
        "    # Prepare the DataFrame for the given date (features must match the training set)\n",
        "    date_features = pd.DataFrame(index=[input_date])\n",
        "\n",
        "    # Add basic date-related features\n",
        "    date_features['day_of_week'] = input_date.weekday  # Weekday as a feature\n",
        "    date_features['day_of_month'] = input_date.day\n",
        "    date_features['month'] = input_date.month\n",
        "    date_features['year'] = input_date.year\n",
        "\n",
        "    # Include price features like 'high', 'low', 'close' if they were used in training\n",
        "    date_features['high'] = df['high'].iloc[-1]  # Last available high\n",
        "    date_features['low'] = df['low'].iloc[-1]  # Last available low\n",
        "    date_features['close'] = df['close'].iloc[-1]  # Last available close\n",
        "    date_features['open'] = df['open'].iloc[-1]  # Last available open\n",
        "\n",
        "    # Add percentage change (assuming this was used in training)\n",
        "    date_features['pct_change'] = df['close'].pct_change().iloc[-1]  # Percentage change from previous close\n",
        "\n",
        "    # Add rolling and lag features (ensure to use the same lags and windows used in training)\n",
        "    for feature in ['high', 'low', 'close', 'open']:\n",
        "        for lag in [30, 60]:\n",
        "            # Only use lag values that exist (i.e., check if the index is available)\n",
        "            if len(df) >= lag:\n",
        "                date_features[f'lag_{lag}_{feature}'] = df[feature].iloc[-lag:].mean()\n",
        "            else:\n",
        "                date_features[f'lag_{lag}_{feature}'] = df[feature].iloc[-1]  # Fallback to most recent value\n",
        "        for window in [30, 60]:\n",
        "            if len(df) >= window:\n",
        "                date_features[f'rolling_{window}_mean_{feature}'] = df[feature].iloc[-window:].mean()\n",
        "                date_features[f'rolling_{window}_std_{feature}'] = df[feature].iloc[-window:].std()\n",
        "            else:\n",
        "                date_features[f'rolling_{window}_mean_{feature}'] = df[feature].iloc[-1]  # Fallback to most recent value\n",
        "                date_features[f'rolling_{window}_std_{feature}'] = df[feature].iloc[-1]  # Use most recent std as default\n",
        "\n",
        "    # Ensure the columns match the training set\n",
        "    missing_columns = [col for col in training_columns if col not in date_features.columns]\n",
        "\n",
        "    # Add missing columns (set them to 0 or NaN, depending on the use case)\n",
        "    for col in missing_columns:\n",
        "        date_features[col] = 0  # Default value for missing columns\n",
        "\n",
        "    # Reorder columns to match the training set\n",
        "    date_features = date_features[training_columns]\n",
        "\n",
        "    return date_features\n",
        "\n",
        "# Example input date (change this to any date you want to predict)\n",
        "input_date = \"2025-04-12\"\n",
        "\n",
        "# Get the features for the input date\n",
        "date_features = preprocess_date_input(input_date, df, X.columns)\n",
        "\n",
        "# Scale the input features using the same scaler that was used for training\n",
        "scaled_date_features = scaler.transform(date_features)\n",
        "\n",
        "# Make prediction with the trained stacking model\n",
        "y_pred_proba = stacking_model.predict_proba(scaled_date_features)[:, 1]  # probabilities for class 1 (Bullish)\n",
        "\n",
        "# Adjust threshold for class 1 (Bullish) prediction\n",
        "threshold = 0.1  # Use a sensible threshold like 0.3 or 0.4 to favor Bullish predictions\n",
        "\n",
        "# If predicted probability >= threshold, predict Bullish (1), otherwise Bearish (0)\n",
        "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Map the prediction to the trend label (0 for Bearish, 1 for Bullish)\n",
        "trend_label = 'Bullish' if y_pred_adjusted[0] == 1 else 'Bearish'\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted Trend for {input_date}: The trend is {trend_label}!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded the stacking model using joblib.load()\n",
        "from joblib import load\n",
        "\n",
        "# Load the trained model (assuming you have saved it previously)\n",
        "stacking_model = load('/content/stacking_model.pkl')\n",
        "\n",
        "# Access the feature names that the model was trained on\n",
        "# X is the DataFrame used for training the model. So, if X is available, you can use:\n",
        "print(X.columns)\n",
        "\n",
        "# Alternatively, if you don't have access to `X`, but you have the scaler:\n",
        "# You can inspect the columns by directly checking the feature names used for scaling:\n",
        "print(\"Columns used for training the stacking model:\", X.columns)"
      ],
      "metadata": {
        "id": "X1MWRk4XoFof"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}